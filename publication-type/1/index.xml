<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>1 | Sarenne</title>
    <link>https://sarenne.github.io/publication-type/1/</link>
      <atom:link href="https://sarenne.github.io/publication-type/1/index.xml" rel="self" type="application/rss+xml" />
    <description>1</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â© `2024`</copyright><lastBuildDate>Sun, 01 Oct 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://sarenne.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>1</title>
      <link>https://sarenne.github.io/publication-type/1/</link>
    </image>
    
    <item>
      <title>Information Value: Measuring Utterance Predictability as Distance from Plausible Alternatives</title>
      <link>https://sarenne.github.io/publication/emnlp2023/</link>
      <pubDate>Sun, 01 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://sarenne.github.io/publication/emnlp2023/</guid>
      <description>&lt;p&gt;In &lt;em&gt;EMNLP 2023&lt;/em&gt;; Singapore&lt;/p&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Quantifying the perceptual value of lexical and non-lexical channels in speech</title>
      <link>https://sarenne.github.io/publication/is2023/</link>
      <pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://sarenne.github.io/publication/is2023/</guid>
      <description>&lt;p&gt;In &lt;em&gt;Interspeech 2023&lt;/em&gt;; Dublin, Ireland&lt;/p&gt;
&lt;p&gt;Check out our stimuli &lt;a href=&#34;https://github.com/Sarenne/is2023&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Do dialogue representations align with perception? An empirical study</title>
      <link>https://sarenne.github.io/publication/eacl2023/</link>
      <pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate>
      <guid>https://sarenne.github.io/publication/eacl2023/</guid>
      <description>&lt;p&gt;In &lt;em&gt;EACL 2023&lt;/em&gt;; Dubrovnik, Croatia&lt;/p&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Investigating perception of spoken dialogue acceptability through surprisal</title>
      <link>https://sarenne.github.io/publication/is2022/</link>
      <pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://sarenne.github.io/publication/is2022/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Awarded ISCA Best Student Paper&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In &lt;em&gt;Interspeech 2022&lt;/em&gt;; Incheon, Korea&lt;/p&gt;
&lt;p&gt;Check out our stimuli &lt;a href=&#34;https://github.com/Sarenne/is2022&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Investigating perception of spoken dialogue acceptability through surprisal</title>
      <link>https://sarenne.github.io/is-2022/</link>
      <pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://sarenne.github.io/is-2022/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;h2&gt;
Stimuli page for work appearing in  &lt;i&gt;Interspeech 2022&lt;/i&gt;
&lt;/h2&gt;
  &lt;h3&gt;
  Abstract:
  &lt;/h3&gt;
  Surprisal is used throughout computational psycholinguistics to model a range of language processing behaviour.
  There is growing evidence that language model (LM) estimates of surprisal correlate with human performance on a range of written language comprehension tasks.
&lt;p&gt;Although communicative interaction is perhaps the primary form of language use, most studies of surprisal employ monological, written data. Towards the goal of understanding perception in spontaneous, natural language, we present an exploratory investigation into whether the relationship between human comprehension behaviour and LM-estimated surprisal holds when applied to dialogue, considering both written dialogue, and the lexical component of spoken dialogue. We use a novel judgement task of dialogue utterance acceptability to ask two questions. &amp;ldquo;How well can people make predictions about written dialogue and transcripts of spoken dialogue?&amp;rdquo; and &amp;ldquo;Does surprisal correlate with these acceptability judgements?&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;We demonstrate that people can make accurate predictions about upcoming dialogue and that their ability differs between spoken transcripts and written conversation. We investigate the relationship between global and local operationalisations of surprisal and human acceptability judgements, finding a combination of both to provide the most predictive power.&lt;/p&gt;
&lt;h3&gt;
Stimuli:
&lt;/h3&gt;
  &lt;blockquote&gt;
  We provide the full sets of stimuli from the Switchboard and DailyDialog corpora along with the plausibility ratings &lt;a href=&#34;https://data.cstr.ed.ac.uk/sarenne/INTERSPEECH2022/&#34;&gt;here &lt;/a&gt;.
  &lt;/blockquote&gt;
&lt;p&gt;The &lt;a href=&#34;https://www.qualtrics.com/&#34;&gt;Qualtrics&lt;/a&gt; survey (constructed using &lt;a href=&#34;https://github.com/CSTR-Edinburgh/qualtreats&#34;&gt;&lt;code&gt;https://github.com/CSTR-Edinburgh/qualtreats&lt;/code&gt;&lt;/a&gt;) was presented to participants through &lt;a href=&#34;https://www.prolific.co/&#34;&gt;Prolific Academic&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;An screenshot of the lexical stimuli presentation is included below while an example of the full survey can be viewed through &lt;a href=&#34;https://edinburghinformatics.eu.qualtrics.com/jfe/form/SV_bEBMmYhvWQPAjDo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this link&lt;/a&gt;.
:
&lt;img src=&#34;screenshots/im1.png&#34; alt=&#34;Flowers in Chania&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>IS2022</title>
      <link>https://sarenne.github.io/project/is2022/</link>
      <pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://sarenne.github.io/project/is2022/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;p&gt;Under construction!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>It&#39;s not what you said, it&#39;s how you said it: discriminative perception of speech as a multichannel communication system</title>
      <link>https://sarenne.github.io/publication/is2021/</link>
      <pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://sarenne.github.io/publication/is2021/</guid>
      <description>&lt;p&gt;In &lt;em&gt;Interspeech 2021&lt;/em&gt;; Brno, Czech Republic&lt;/p&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>It&#39;s not what you said, it&#39;s how you said it: discriminative perception of speech as a multichannel communication system EVENT</title>
      <link>https://sarenne.github.io/talk/its-not-what-you-said-its-how-you-said-it-discriminative-perception-of-speech-as-a-multichannel-communication-system-event/</link>
      <pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://sarenne.github.io/talk/its-not-what-you-said-its-how-you-said-it-discriminative-perception-of-speech-as-a-multichannel-communication-system-event/</guid>
      <description>&lt;p&gt;In &lt;em&gt;Interspeech 2021&lt;/em&gt;; Brno, Czech Republic&lt;/p&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Quantifying the perceptual value of lexical and non-lexical channels in speech</title>
      <link>https://sarenne.github.io/is-2023/</link>
      <pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://sarenne.github.io/is-2023/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;h2&gt;
Stimuli page for work appearing in &lt;i&gt;Interspeech 2023&lt;/i&gt; 
&lt;/h2&gt;
  &lt;h3&gt;
  Abstract:
  &lt;/h3&gt;
    Speech is a fundamental means of communication that can be seen to provide two channels for transmitting information: the lexical channel of which words are said, and the non-lexical channel of *how* they are spoken. Both channels shape listener expectations of upcoming communication; however, directly quantifying their relative effect on expectations is challenging. Previous attempts require spoken variations of lexically-equivalent dialogue turns or conspicuous acoustic manipulations. This paper introduces a generalised paradigm to study the value of non-lexical information in dialogue across unconstrained lexical content. By quantifying the perceptual value of the non-lexical channel with both accuracy and entropy reduction, we show that non-lexical information produces a consistent effect on expectations of upcoming dialogue: even when it leads to poorer discriminative turn judgements than lexical content alone, it yields higher consensus among participants
&lt;h3&gt;
Stimuli:
&lt;/h3&gt;
  &lt;blockquote&gt;
  We provide the full sets of stimuli constructed from the Switchboard corpus along with their associated ratings &lt;a href=&#34;https://data.cstr.ed.ac.uk/sarenne/INTERSPEECH2023/&#34;&gt;here &lt;/a&gt;.
  &lt;/blockquote&gt;
&lt;p&gt;The &lt;a href=&#34;https://www.qualtrics.com/&#34;&gt;Qualtrics&lt;/a&gt; survey (constructed using &lt;a href=&#34;https://github.com/CSTR-Edinburgh/qualtreats&#34;&gt;&lt;code&gt;https://github.com/CSTR-Edinburgh/qualtreats&lt;/code&gt;&lt;/a&gt;) was presented to participants through &lt;a href=&#34;https://www.prolific.co/&#34;&gt;Prolific Academic&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Examples of our presentation in the lexical condition are included below.  Additionally, we provide an example stimulus in the acoustic condition through &lt;a href=&#34;https://edinburghinformatics.eu.qualtrics.com/jfe/form/SV_cBg4zwtjHYAlZB4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A lexical stimuli:
&lt;img src=&#34;screenshots/lexical_stimuli.png&#34; alt=&#34;Lexical stimuli question&#34;&gt;
A lexical check question:
&lt;img src=&#34;screenshots/lexical_check.png&#34; alt=&#34;Lexical check question&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exploring the Relationship Between Word Form and Word Meaning</title>
      <link>https://sarenne.github.io/talk/exploring-the-relationship-between-word-form-and-word-meaning/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      <guid>https://sarenne.github.io/talk/exploring-the-relationship-between-word-form-and-word-meaning/</guid>
      <description>&lt;p&gt;Supervised by Sharon Goldwater.&lt;/p&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Exploring the Relationship Between Word Form and Word Meaning</title>
      <link>https://sarenne.github.io/publication/ug-thesis/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      <guid>https://sarenne.github.io/publication/ug-thesis/</guid>
      <description>&lt;p&gt;Supervised by Sharon Goldwater.&lt;/p&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
  </channel>
</rss>
